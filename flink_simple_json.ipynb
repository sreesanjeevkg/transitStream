{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab5389cc-df05-4dff-8354-0444e2adee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from pyflink.common import WatermarkStrategy\n",
    "from pyflink.datastream import StreamExecutionEnvironment, RuntimeExecutionMode\n",
    "from pyflink.datastream.connectors.kafka import KafkaSource, KafkaOffsetsInitializer\n",
    "from pyflink.datastream.formats.json import JsonRowDeserializationSchema\n",
    "from pyflink.common import Types, Row\n",
    "from pyflink.datastream.connectors.jdbc import JdbcSink, JdbcConnectionOptions, JdbcExecutionOptions\n",
    "from pyflink.datastream.connectors.kafka import KafkaTopicPartition\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "RUNTIME_ENV = os.getenv(\"RUNTIME_ENV\", \"local\")\n",
    "BOOTSTRAP_SERVERS = os.getenv(\"BOOTSTRAP_SERVERS\", \"localhost:9092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edff9cb0-da05-4d2f-b7e4-cea5bbfe7962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaObject id=o365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "env.set_runtime_mode(RuntimeExecutionMode.STREAMING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0707ef6b-dbdb-426f-a17a-d95f9f24587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_files = [\"flink-sql-connector-kafka-3.2.0-1.18.jar\", \"postgresql-42.6.0.jar\", \"flink-connector-jdbc-3.1.2-1.18.jar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75f45706-a5d5-4129-b0b7-f205f38be838",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1913271-0fe1-49c9-986c-5a3c42034dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_type = Types.ROW_NAMED(['delay', 'time', 'uncertainty'], [Types.INT(), Types.INT(), Types.INT()])\n",
    "arrival_type = Types.ROW_NAMED(['delay', 'time', 'uncertainty'], [Types.INT(), Types.INT(), Types.INT()])\n",
    "stop_time_update_type = Types.ROW_NAMED(['stop_sequence', 'arrival', 'departure', 'stop_id', 'schedule_relationship'], [Types.INT(), arrival_type, departure_type, Types.STRING(), Types.INT()])\n",
    "vehicle_type_info = Types.ROW_NAMED(['id', 'label', 'license_plate'], [Types.STRING(), Types.STRING(), Types.STRING()])\n",
    "trip_update_trip_info = Types.ROW_NAMED(['trip_id', 'start_time', 'start_date', 'schedule_relationship', 'route_id', 'direction_id'], [Types.STRING(), Types.STRING(), Types.STRING(), Types.INT(), Types.STRING(), Types.INT()])\n",
    "trip_update_type = Types.ROW_NAMED(['trip', 'stop_time_update', 'vehicle', 'timestamp', 'delay'],[trip_update_trip_info, Types.OBJECT_ARRAY(stop_time_update_type), Types.STRING(), Types.STRING(), Types.INT()])\n",
    "trip_info_type = Types.ROW_NAMED(['id', 'is_deleted', 'trip_update', 'vehicle', 'alert'], [Types.STRING(), Types.BOOLEAN(), trip_update_type, Types.STRING(), Types.STRING()])\n",
    "json_format = JsonRowDeserializationSchema.builder().type_info(trip_info_type).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc949493-2eb5-4112-ab14-79501176613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_paths = tuple(\n",
    "            [f\"file://{os.path.join(CURRENT_DIR, 'Downloads', name)}\" for name in jar_files]\n",
    "        )\n",
    "logging.info(f\"adding local jars - {', '.join(jar_files)}\")\n",
    "env.add_jars(*jar_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86ea877a-b530-4f5b-a9ad-01cde789c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_set = {\n",
    "    KafkaTopicPartition(\"transitStream\", 0)\n",
    "}\n",
    "\n",
    "flink_simple_json_source = (\n",
    "        KafkaSource.builder()\n",
    "        .set_bootstrap_servers(BOOTSTRAP_SERVERS)\n",
    "        .set_group_id(\"flink.testertransit\")\n",
    "        .set_starting_offsets(KafkaOffsetsInitializer.earliest())\n",
    "        .set_value_only_deserializer(\n",
    "            json_format\n",
    "        )\n",
    "        .set_partitions(partition_set)\n",
    "        .build()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b8b4c99-1e24-4018-a827-b4934819577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flink_stream = env.from_source(\n",
    "        flink_simple_json_source, WatermarkStrategy.no_watermarks(), \"what is this\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9525a1c6-7ac4-4573-ba82-ce6793de9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trip_info(row):\n",
    "    trip_id = row.id\n",
    "    start_time = datetime.strptime(row.trip_update.trip.start_time, \"%H:%M:%S\")\n",
    "    start_date = datetime.strptime(row.trip_update.trip.start_date, \"%Y%m%d\")\n",
    "    for stops in row.trip_update.stop_time_update:\n",
    "        stop_seq = stops.stop_sequence\n",
    "        if stops.departure is not None:\n",
    "            if stops.departure.delay > 0:\n",
    "                delay_in_seconds = stops.departure.delay\n",
    "                status = \"delayed\"\n",
    "            elif stops.departure.delay < 0:\n",
    "                delay_in_seconds = abs(stops.departure.delay)\n",
    "                status = \"early\"\n",
    "            else:\n",
    "                delay_in_seconds = stops.departure.delay\n",
    "                status = \"running on time\"\n",
    "            stop_time = datetime.fromtimestamp(stops.departure.time)\n",
    "        else:\n",
    "            if stops.arrival.delay > 0:\n",
    "                delay_in_seconds = stops.arrival.delay\n",
    "                status = \"delayed\"\n",
    "            elif stops.arrival.delay < 0:\n",
    "                delay_in_seconds = abs(stops.arrival.delay)\n",
    "                status = \"early\"\n",
    "            else:\n",
    "                delay_in_seconds = stops.arrival.delay\n",
    "                status = \"running on time\"\n",
    "            stop_time = datetime.fromtimestamp(stops.arrival.time)\n",
    "        yield Row(trip_id, start_time, start_date, stop_seq, stop_time, delay_in_seconds, status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90f2b770-8c42-4a99-99d0-6012aab385ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.datastream.data_stream.DataStreamSink at 0x12e683970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_type_info = Types.ROW([Types.STRING(), Types.SQL_TIME(), Types.SQL_DATE(), Types.INT(),Types.SQL_TIMESTAMP(), Types.INT(), Types.STRING()])\n",
    "\n",
    "flink_stream.flat_map(extract_trip_info, output_type = row_type_info).add_sink(\n",
    "    JdbcSink.sink(\n",
    "        \"\"\"INSERT INTO public.trip_updates (trip_id, start_time, start_date, stop_seq, stop_time, delay_in_sec, status)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?) \n",
    "            ON CONFLICT (trip_id, start_date, stop_seq, u) \n",
    "            DO UPDATE SET \n",
    "            trip_id = EXCLUDED.trip_id,\n",
    "            start_time = EXCLUDED.start_time,\n",
    "            start_date = EXCLUDED.start_date,\n",
    "            stop_seq = EXCLUDED.stop_seq,\n",
    "            stop_time = EXCLUDED.stop_time,\n",
    "            delay_in_sec = EXCLUDED.delay_in_sec,\n",
    "            status = EXCLUDED.status\n",
    "        \"\"\",\n",
    "        row_type_info,\n",
    "        JdbcConnectionOptions.JdbcConnectionOptionsBuilder()\n",
    "            .with_url('jdbc:postgresql://localhost:5432/transitstreamtest')\n",
    "            .with_driver_name('org.postgresql.Driver')\n",
    "            .with_user_name('root')\n",
    "            .with_password('root')\n",
    "            .build(),\n",
    "        JdbcExecutionOptions.builder()\n",
    "            .with_batch_interval_ms(1000)\n",
    "            .with_batch_size(200)\n",
    "            .with_max_retries(2)\n",
    "            .build()\n",
    ")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e524aa07-4357-4517-945a-5318ca468890",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o354.execute.\n: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)\n\tat org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)\n\tat java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:646)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoInvocationHandler.lambda$invokeRpc$1(PekkoInvocationHandler.java:268)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1287)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.runtime.concurrent.pekko.ScalaFutureUtils$1.onComplete(ScalaFutureUtils.java:47)\n\tat org.apache.pekko.dispatch.OnComplete.internal(Future.scala:310)\n\tat org.apache.pekko.dispatch.OnComplete.internal(Future.scala:307)\n\tat org.apache.pekko.dispatch.japi$CallbackBridge.apply(Future.scala:234)\n\tat org.apache.pekko.dispatch.japi$CallbackBridge.apply(Future.scala:231)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.flink.runtime.concurrent.pekko.ScalaFutureUtils$DirectExecutionContext.execute(ScalaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n\tat org.apache.pekko.pattern.PromiseActorRef.$bang(AskSupport.scala:629)\n\tat org.apache.pekko.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:34)\n\tat org.apache.pekko.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:33)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:536)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.pekko.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:73)\n\tat org.apache.pekko.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat org.apache.pekko.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:110)\n\tat org.apache.pekko.dispatch.TaskInvocation.run(AbstractDispatcher.scala:59)\n\tat org.apache.pekko.dispatch.ForkJoinExecutorConfigurator$PekkoForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:57)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:507)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1491)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:2073)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:2035)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:187)\nCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy\n\tat org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:180)\n\tat org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:107)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:277)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:268)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:261)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:787)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:764)\n\tat org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)\n\tat org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:488)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:309)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:307)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:222)\n\tat org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:85)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:168)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)\n\tat scala.PartialFunction.applyOrElse(PartialFunction.scala:127)\n\tat scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)\n\tat org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)\n\tat org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)\n\tat org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)\n\tat org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)\n\tat org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)\n\tat org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:280)\n\tat org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:241)\n\tat org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:253)\n\t... 5 more\nCaused by: org.apache.flink.runtime.taskmanager.AsynchronousException: Caught exception while processing timer.\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask$StreamTaskAsyncExceptionHandler.handleAsyncException(StreamTask.java:1642)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.handleAsyncException(StreamTask.java:1617)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1771)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$null$25(StreamTask.java:1760)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:909)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:858)\n\tat org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:958)\n\tat org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:937)\n\tat org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:751)\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\nCaused by: TimerException{org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator}\n\t... 15 more\nCaused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:92)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:50)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29)\n\tat org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:52)\n\tat org.apache.flink.streaming.api.operators.python.process.collector.RunnerOutputCollector.collect(RunnerOutputCollector.java:52)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalOneInputPythonFunctionOperator.emitResult(AbstractExternalOneInputPythonFunctionOperator.java:133)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalPythonFunctionOperator.emitResults(AbstractExternalPythonFunctionOperator.java:142)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalPythonFunctionOperator.invokeFinishBundle(AbstractExternalPythonFunctionOperator.java:101)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.checkInvokeFinishBundleByTime(AbstractPythonFunctionOperator.java:300)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.lambda$open$0(AbstractPythonFunctionOperator.java:118)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1769)\n\t... 14 more\nCaused by: java.io.IOException: Writing records to JDBC failed.\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.writeRecord(JdbcOutputFormat.java:198)\n\tat org.apache.flink.connector.jdbc.internal.GenericJdbcSinkFunction.invoke(GenericJdbcSinkFunction.java:57)\n\tat org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:54)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:75)\n\t... 24 more\nCaused by: java.io.IOException: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO public.trip_updates (trip_id, start_time, start_date, stop_seq, stop_time, delay_in_sec, status)\n            VALUES ('1181513', '16:02:00-06', '2024-07-17 -05', 56, '2024-07-17 16:47:54-05', 0, 'running on time') \n            ON CONFLICT (trip_id, start_date, stop_seq, u) \n            DO UPDATE SET \n            trip_id = EXCLUDED.trip_id,\n            start_time = EXCLUDED.start_time,\n            start_date = EXCLUDED.start_date,\n            stop_seq = EXCLUDED.stop_seq,\n            stop_time = EXCLUDED.stop_time,\n            delay_in_sec = EXCLUDED.delay_in_sec,\n            status = EXCLUDED.status\n         was aborted: ERROR: column \"u\" does not exist\n  Position: 183  Call getNextException to see other errors in the batch.\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.flush(JdbcOutputFormat.java:222)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.writeRecord(JdbcOutputFormat.java:195)\n\t... 27 more\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO public.trip_updates (trip_id, start_time, start_date, stop_seq, stop_time, delay_in_sec, status)\n            VALUES ('1181513', '16:02:00-06', '2024-07-17 -05', 56, '2024-07-17 16:47:54-05', 0, 'running on time') \n            ON CONFLICT (trip_id, start_date, stop_seq, u) \n            DO UPDATE SET \n            trip_id = EXCLUDED.trip_id,\n            start_time = EXCLUDED.start_time,\n            start_date = EXCLUDED.start_date,\n            stop_seq = EXCLUDED.stop_seq,\n            stop_time = EXCLUDED.stop_time,\n            delay_in_sec = EXCLUDED.delay_in_sec,\n            status = EXCLUDED.status\n         was aborted: ERROR: column \"u\" does not exist\n  Position: 183  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleCompletion(BatchResultHandler.java:186)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:881)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.flink.connector.jdbc.internal.executor.SimpleBatchStatementExecutor.executeBatch(SimpleBatchStatementExecutor.java:73)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.attemptFlush(JdbcOutputFormat.java:246)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.flush(JdbcOutputFormat.java:216)\n\t... 28 more\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"u\" does not exist\n  Position: 183\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 33 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pyflink/datastream/stream_execution_environment.py:813\u001b[0m, in \u001b[0;36mStreamExecutionEnvironment.execute\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;124;03mTriggers the program execution. The environment will execute all parts of\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;124;03mthe program that have resulted in a \"sink\" operation. Sink operations are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m:return: The result of the job execution, containing elapsed time and accumulators.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m j_stream_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_stream_graph(clear_transformations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m JobExecutionResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_j_stream_execution_environment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_stream_graph\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pyflink/util/exceptions.py:146\u001b[0m, in \u001b[0;36mcapture_java_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjava_gateway\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gateway\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o354.execute.\n: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)\n\tat org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)\n\tat java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:646)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoInvocationHandler.lambda$invokeRpc$1(PekkoInvocationHandler.java:268)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1287)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2179)\n\tat org.apache.flink.runtime.concurrent.pekko.ScalaFutureUtils$1.onComplete(ScalaFutureUtils.java:47)\n\tat org.apache.pekko.dispatch.OnComplete.internal(Future.scala:310)\n\tat org.apache.pekko.dispatch.OnComplete.internal(Future.scala:307)\n\tat org.apache.pekko.dispatch.japi$CallbackBridge.apply(Future.scala:234)\n\tat org.apache.pekko.dispatch.japi$CallbackBridge.apply(Future.scala:231)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.flink.runtime.concurrent.pekko.ScalaFutureUtils$DirectExecutionContext.execute(ScalaFutureUtils.java:65)\n\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n\tat org.apache.pekko.pattern.PromiseActorRef.$bang(AskSupport.scala:629)\n\tat org.apache.pekko.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:34)\n\tat org.apache.pekko.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:33)\n\tat scala.concurrent.Future.$anonfun$andThen$1(Future.scala:536)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.pekko.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:73)\n\tat org.apache.pekko.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n\tat org.apache.pekko.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:110)\n\tat org.apache.pekko.dispatch.TaskInvocation.run(AbstractDispatcher.scala:59)\n\tat org.apache.pekko.dispatch.ForkJoinExecutorConfigurator$PekkoForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:57)\n\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:507)\n\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1491)\n\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:2073)\n\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:2035)\n\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:187)\nCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy\n\tat org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:180)\n\tat org.apache.flink.runtime.executiongraph.failover.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:107)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:277)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:268)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:261)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:787)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:764)\n\tat org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:83)\n\tat org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:488)\n\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.lambda$handleRpcInvocation$1(PekkoRpcActor.java:309)\n\tat org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcInvocation(PekkoRpcActor.java:307)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleRpcMessage(PekkoRpcActor.java:222)\n\tat org.apache.flink.runtime.rpc.pekko.FencedPekkoRpcActor.handleRpcMessage(FencedPekkoRpcActor.java:85)\n\tat org.apache.flink.runtime.rpc.pekko.PekkoRpcActor.handleMessage(PekkoRpcActor.java:168)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:33)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:29)\n\tat scala.PartialFunction.applyOrElse(PartialFunction.scala:127)\n\tat scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)\n\tat org.apache.pekko.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:29)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)\n\tat org.apache.pekko.actor.Actor.aroundReceive(Actor.scala:547)\n\tat org.apache.pekko.actor.Actor.aroundReceive$(Actor.scala:545)\n\tat org.apache.pekko.actor.AbstractActor.aroundReceive(AbstractActor.scala:229)\n\tat org.apache.pekko.actor.ActorCell.receiveMessage(ActorCell.scala:590)\n\tat org.apache.pekko.actor.ActorCell.invoke(ActorCell.scala:557)\n\tat org.apache.pekko.dispatch.Mailbox.processMailbox(Mailbox.scala:280)\n\tat org.apache.pekko.dispatch.Mailbox.run(Mailbox.scala:241)\n\tat org.apache.pekko.dispatch.Mailbox.exec(Mailbox.scala:253)\n\t... 5 more\nCaused by: org.apache.flink.runtime.taskmanager.AsynchronousException: Caught exception while processing timer.\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask$StreamTaskAsyncExceptionHandler.handleAsyncException(StreamTask.java:1642)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.handleAsyncException(StreamTask.java:1617)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1771)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$null$25(StreamTask.java:1760)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)\n\tat org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:909)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:858)\n\tat org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:958)\n\tat org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:937)\n\tat org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:751)\n\tat org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)\n\tat java.base/java.lang.Thread.run(Thread.java:1570)\nCaused by: TimerException{org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator}\n\t... 15 more\nCaused by: org.apache.flink.streaming.runtime.tasks.ExceptionInChainedOperatorException: Could not forward element to next operator\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:92)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:50)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:29)\n\tat org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:52)\n\tat org.apache.flink.streaming.api.operators.python.process.collector.RunnerOutputCollector.collect(RunnerOutputCollector.java:52)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalOneInputPythonFunctionOperator.emitResult(AbstractExternalOneInputPythonFunctionOperator.java:133)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalPythonFunctionOperator.emitResults(AbstractExternalPythonFunctionOperator.java:142)\n\tat org.apache.flink.streaming.api.operators.python.process.AbstractExternalPythonFunctionOperator.invokeFinishBundle(AbstractExternalPythonFunctionOperator.java:101)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.checkInvokeFinishBundleByTime(AbstractPythonFunctionOperator.java:300)\n\tat org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator.lambda$open$0(AbstractPythonFunctionOperator.java:118)\n\tat org.apache.flink.streaming.runtime.tasks.StreamTask.invokeProcessingTimeCallback(StreamTask.java:1769)\n\t... 14 more\nCaused by: java.io.IOException: Writing records to JDBC failed.\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.writeRecord(JdbcOutputFormat.java:198)\n\tat org.apache.flink.connector.jdbc.internal.GenericJdbcSinkFunction.invoke(GenericJdbcSinkFunction.java:57)\n\tat org.apache.flink.streaming.api.operators.StreamSink.processElement(StreamSink.java:54)\n\tat org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:75)\n\t... 24 more\nCaused by: java.io.IOException: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO public.trip_updates (trip_id, start_time, start_date, stop_seq, stop_time, delay_in_sec, status)\n            VALUES ('1181513', '16:02:00-06', '2024-07-17 -05', 56, '2024-07-17 16:47:54-05', 0, 'running on time') \n            ON CONFLICT (trip_id, start_date, stop_seq, u) \n            DO UPDATE SET \n            trip_id = EXCLUDED.trip_id,\n            start_time = EXCLUDED.start_time,\n            start_date = EXCLUDED.start_date,\n            stop_seq = EXCLUDED.stop_seq,\n            stop_time = EXCLUDED.stop_time,\n            delay_in_sec = EXCLUDED.delay_in_sec,\n            status = EXCLUDED.status\n         was aborted: ERROR: column \"u\" does not exist\n  Position: 183  Call getNextException to see other errors in the batch.\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.flush(JdbcOutputFormat.java:222)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.writeRecord(JdbcOutputFormat.java:195)\n\t... 27 more\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO public.trip_updates (trip_id, start_time, start_date, stop_seq, stop_time, delay_in_sec, status)\n            VALUES ('1181513', '16:02:00-06', '2024-07-17 -05', 56, '2024-07-17 16:47:54-05', 0, 'running on time') \n            ON CONFLICT (trip_id, start_date, stop_seq, u) \n            DO UPDATE SET \n            trip_id = EXCLUDED.trip_id,\n            start_time = EXCLUDED.start_time,\n            start_date = EXCLUDED.start_date,\n            stop_seq = EXCLUDED.stop_seq,\n            stop_time = EXCLUDED.stop_time,\n            delay_in_sec = EXCLUDED.delay_in_sec,\n            status = EXCLUDED.status\n         was aborted: ERROR: column \"u\" does not exist\n  Position: 183  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleCompletion(BatchResultHandler.java:186)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:881)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:919)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.flink.connector.jdbc.internal.executor.SimpleBatchStatementExecutor.executeBatch(SimpleBatchStatementExecutor.java:73)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.attemptFlush(JdbcOutputFormat.java:246)\n\tat org.apache.flink.connector.jdbc.internal.JdbcOutputFormat.flush(JdbcOutputFormat.java:216)\n\t... 28 more\nCaused by: org.postgresql.util.PSQLException: ERROR: column \"u\" does not exist\n  Position: 183\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:327)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:877)\n\t... 33 more\n"
     ]
    }
   ],
   "source": [
    "env.execute(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea21e3-e0b4-4230-990f-d2ec998b1e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
